{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìä Data Quality Analysis Report\n",
    "## Retail Sales Dataset - Preprocessing Assessment\n",
    "\n",
    "**Purpose:** Identify data quality issues and recommend preprocessing steps\n",
    "\n",
    "**Author:** Retail Insights Assistant Team  \n",
    "**Date:** February 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ 1. Amazon Sales Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Amazon Sales data\n",
    "amazon_df = pd.read_csv('Sales Dataset/Amazon Sale Report.csv', low_memory=False)\n",
    "\n",
    "print(\"üìä Amazon Sales Dataset\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Rows: {len(amazon_df):,}\")\n",
    "print(f\"Total Columns: {len(amazon_df.columns)}\")\n",
    "print(f\"Memory Usage: {amazon_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Types & Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data types\n",
    "print(\"Column Data Types:\")\n",
    "print(\"=\" * 80)\n",
    "amazon_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = amazon_df.isnull().sum()\n",
    "missing_pct = (missing / len(amazon_df) * 100)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing.index,\n",
    "    'Missing Count': missing.values,\n",
    "    'Missing %': missing_pct.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Missing Values Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(missing_df.to_string(index=False))\n",
    "\n",
    "# Visualize missing values\n",
    "if len(missing_df) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(missing_df['Column'], missing_df['Missing %'], color='coral')\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.title('Missing Values by Column (Amazon Sales)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Order Status Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status distribution\n",
    "print(\"\\nüì¶ Order Status Distribution:\")\n",
    "print(\"=\" * 80)\n",
    "status_counts = amazon_df['Status'].value_counts()\n",
    "status_pct = (status_counts / len(amazon_df) * 100)\n",
    "\n",
    "status_summary = pd.DataFrame({\n",
    "    'Status': status_counts.index,\n",
    "    'Count': status_counts.values,\n",
    "    'Percentage': status_pct.values\n",
    "})\n",
    "print(status_summary.to_string(index=False))\n",
    "\n",
    "# Visualize status distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Pie chart\n",
    "ax1.pie(status_counts.head(6), labels=status_counts.head(6).index, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Top 6 Order Statuses')\n",
    "\n",
    "# Bar chart\n",
    "status_counts.head(10).plot(kind='barh', ax=ax2, color='skyblue')\n",
    "ax2.set_xlabel('Number of Orders')\n",
    "ax2.set_title('Top 10 Order Statuses')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Highlight cancelled orders\n",
    "cancelled = amazon_df[amazon_df['Status'] == 'Cancelled']\n",
    "print(f\"\\n‚ö†Ô∏è  CRITICAL: {len(cancelled):,} Cancelled Orders ({len(cancelled)/len(amazon_df)*100:.2f}%)\")\n",
    "print(f\"   These should be EXCLUDED from revenue calculations!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Amount/Revenue Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount analysis\n",
    "print(\"\\nüí∞ Amount/Revenue Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Min Amount: ‚Çπ{amazon_df['Amount'].min():.2f}\")\n",
    "print(f\"Max Amount: ‚Çπ{amazon_df['Amount'].max():.2f}\")\n",
    "print(f\"Mean Amount: ‚Çπ{amazon_df['Amount'].mean():.2f}\")\n",
    "print(f\"Median Amount: ‚Çπ{amazon_df['Amount'].median():.2f}\")\n",
    "print(f\"\\nZero or Negative Amounts: {(amazon_df['Amount'] <= 0).sum():,} ({(amazon_df['Amount'] <= 0).sum()/len(amazon_df)*100:.2f}%)\")\n",
    "\n",
    "# Visualize amount distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Histogram\n",
    "amazon_df[amazon_df['Amount'] > 0]['Amount'].hist(bins=50, ax=ax1, color='green', alpha=0.7)\n",
    "ax1.set_xlabel('Amount (‚Çπ)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Amount Distribution (Excluding Zero/Negative)')\n",
    "\n",
    "# Box plot\n",
    "amazon_df[amazon_df['Amount'] > 0]['Amount'].plot(kind='box', ax=ax2, vert=False)\n",
    "ax2.set_xlabel('Amount (‚Çπ)')\n",
    "ax2.set_title('Amount Box Plot (Outliers Detection)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Date Format Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date analysis\n",
    "print(\"\\nüìÖ Date Format Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Sample dates: {amazon_df['Date'].dropna().head(10).tolist()}\")\n",
    "print(f\"Unique dates: {amazon_df['Date'].nunique():,}\")\n",
    "print(f\"Date format: MM-DD-YY (STRING - needs conversion to DATE type)\")\n",
    "\n",
    "# Count orders by date\n",
    "date_counts = amazon_df['Date'].value_counts().sort_index().head(30)\n",
    "plt.figure(figsize=(14, 6))\n",
    "date_counts.plot(kind='line', marker='o', color='purple')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.title('Orders Over Time (First 30 Days)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category analysis\n",
    "print(\"\\nüè∑Ô∏è  Category Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "category_counts = amazon_df['Category'].value_counts().head(15)\n",
    "print(category_counts)\n",
    "\n",
    "# Visualize top categories\n",
    "plt.figure(figsize=(12, 6))\n",
    "category_counts.plot(kind='barh', color='teal')\n",
    "plt.xlabel('Number of Orders')\n",
    "plt.title('Top 15 Product Categories')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ 2. International Sales Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load International Sales data\n",
    "intl_df = pd.read_csv('Sales Dataset/International sale Report.csv', low_memory=False)\n",
    "\n",
    "print(\"üìä International Sales Dataset\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Rows: {len(intl_df):,}\")\n",
    "print(f\"Total Columns: {len(intl_df.columns)}\")\n",
    "print(f\"Memory Usage: {intl_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "intl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing_intl = intl_df.isnull().sum()\n",
    "missing_pct_intl = (missing_intl / len(intl_df) * 100)\n",
    "missing_df_intl = pd.DataFrame({\n",
    "    'Column': missing_intl.index,\n",
    "    'Missing Count': missing_intl.values,\n",
    "    'Missing %': missing_pct_intl.values\n",
    "})\n",
    "missing_df_intl = missing_df_intl[missing_df_intl['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Missing Values Analysis (International):\")\n",
    "print(\"=\" * 80)\n",
    "print(missing_df_intl.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "if len(missing_df_intl) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(missing_df_intl['Column'], missing_df_intl['Missing %'], color='orange')\n",
    "    plt.xlabel('Missing Percentage (%)')\n",
    "    plt.title('Missing Values by Column (International Sales)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ 3. Sale Report (Inventory) Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sale Report data\n",
    "inventory_df = pd.read_csv('Sales Dataset/Sale Report.csv', low_memory=False)\n",
    "\n",
    "print(\"üìä Sale Report (Inventory) Dataset\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total Rows: {len(inventory_df):,}\")\n",
    "print(f\"Total Columns: {len(inventory_df.columns)}\")\n",
    "print(f\"Memory Usage: {inventory_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "inventory_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing_inv = inventory_df.isnull().sum()\n",
    "missing_pct_inv = (missing_inv / len(inventory_df) * 100)\n",
    "missing_df_inv = pd.DataFrame({\n",
    "    'Column': missing_inv.index,\n",
    "    'Missing Count': missing_inv.values,\n",
    "    'Missing %': missing_pct_inv.values\n",
    "})\n",
    "missing_df_inv = missing_df_inv[missing_df_inv['Missing Count'] > 0].sort_values('Missing %', ascending=False)\n",
    "\n",
    "print(\"\\nüîç Missing Values Analysis (Inventory):\")\n",
    "print(\"=\" * 80)\n",
    "print(missing_df_inv.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## üìÅ 4. Product Pricing Catalogs Analysis (May-2022 & P L March 2021)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ 4. Summary of Data Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìã DATA QUALITY ISSUES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüî¥ CRITICAL ISSUES (Must Fix):\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"1. Cancelled Orders: {len(cancelled):,} orders (14.21%) - EXCLUDE from revenue\")\n",
    "print(f\"2. Missing Amounts: {amazon_df['Amount'].isnull().sum():,} records (6.04%)\")\n",
    "print(f\"3. Zero/Negative Amounts: {(amazon_df['Amount'] <= 0).sum():,} records (1.82%)\")\n",
    "print(f\"4. Date Format: All dates are STRING type - need conversion to DATE\")\n",
    "\n",
    "print(\"\\nüü° MEDIUM PRIORITY:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"5. Missing promotion-ids: {amazon_df['promotion-ids'].isnull().sum():,} (38.11%) - OK if not used\")\n",
    "print(f\"6. Missing fulfilled-by: {amazon_df['fulfilled-by'].isnull().sum():,} (69.55%) - OK if not used\")\n",
    "print(f\"7. International Sales missing: ~1,040 rows with NULL customer data (2.78%)\")\n",
    "\n",
    "print(\"\\nüü¢ LOW PRIORITY:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"8. Inventory dataset: Minor missing values (~0.5%)\")\n",
    "print(\"9. No duplicate rows detected - GOOD!\")\n",
    "print(\"10. Text standardization needed (state names, categories)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ 5. Recommended Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí° RECOMMENDED PREPROCESSING PIPELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = \"\"\"\n",
    "STEP 1: Remove Cancelled Orders\n",
    "----------------------------------------\n",
    "Filter: Status != 'Cancelled'\n",
    "Impact: Removes 18,332 cancelled orders\n",
    "Result: Revenue accuracy improves by ~10%\n",
    "\n",
    "STEP 2: Handle Missing/Invalid Amounts\n",
    "----------------------------------------\n",
    "Action: Drop rows where Amount IS NULL OR Amount <= 0\n",
    "Impact: Removes ~10,138 problematic records\n",
    "Result: Clean revenue data for calculations\n",
    "\n",
    "STEP 3: Parse Dates to Proper Type\n",
    "----------------------------------------\n",
    "Convert: 'MM-DD-YY' (string) ‚Üí DATE type\n",
    "Add: year, month, quarter columns\n",
    "Impact: Enables time-series analysis\n",
    "Result: Can do YoY, monthly trends, seasonal analysis\n",
    "\n",
    "STEP 4: Standardize Text Fields\n",
    "----------------------------------------\n",
    "ship-state: Convert to UPPERCASE, trim whitespace\n",
    "Category: Standardize naming conventions\n",
    "Impact: Consistent aggregations\n",
    "Result: Accurate category/region grouping\n",
    "\n",
    "STEP 5: Handle International Sales NULLs\n",
    "----------------------------------------\n",
    "Action: Drop rows with NULL CUSTOMER/GROSS AMT\n",
    "Impact: Removes ~1,040 incomplete records (2.78%)\n",
    "Result: Clean international sales data\n",
    "\n",
    "EXPECTED OUTCOME:\n",
    "‚úÖ Clean dataset: ~100,000 valid Amazon orders (from 128,975)\n",
    "‚úÖ Accurate revenue calculations\n",
    "‚úÖ Time-series analysis enabled\n",
    "‚úÖ Consistent text fields\n",
    "‚úÖ Production-ready data quality\n",
    "\"\"\"\n",
    "\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä 6. Impact Analysis: Before vs After Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate impact\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà PREPROCESSING IMPACT ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Before preprocessing\n",
    "total_before = len(amazon_df)\n",
    "revenue_before = amazon_df['Amount'].sum()\n",
    "\n",
    "# After preprocessing (simulated)\n",
    "clean_df = amazon_df[\n",
    "    (amazon_df['Status'] != 'Cancelled') & \n",
    "    (amazon_df['Amount'].notna()) & \n",
    "    (amazon_df['Amount'] > 0)\n",
    "]\n",
    "total_after = len(clean_df)\n",
    "revenue_after = clean_df['Amount'].sum()\n",
    "\n",
    "print(f\"\\nBEFORE Preprocessing:\")\n",
    "print(f\"  Total Records: {total_before:,}\")\n",
    "print(f\"  Total Revenue: ‚Çπ{revenue_before:,.2f}\")\n",
    "print(f\"  Avg Order Value: ‚Çπ{revenue_before/total_before:.2f}\")\n",
    "\n",
    "print(f\"\\nAFTER Preprocessing:\")\n",
    "print(f\"  Total Records: {total_after:,}\")\n",
    "print(f\"  Total Revenue: ‚Çπ{revenue_after:,.2f}\")\n",
    "print(f\"  Avg Order Value: ‚Çπ{revenue_after/total_after:.2f}\")\n",
    "\n",
    "print(f\"\\nIMPACT:\")\n",
    "print(f\"  Records Removed: {total_before - total_after:,} ({(total_before - total_after)/total_before*100:.2f}%)\")\n",
    "print(f\"  Revenue Difference: ‚Çπ{revenue_before - revenue_after:,.2f}\")\n",
    "print(f\"  Accuracy Improvement: ~{abs(revenue_before - revenue_after)/revenue_before*100:.1f}%\")\n",
    "\n",
    "# Visualize impact\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Records comparison\n",
    "ax1.bar(['Before', 'After'], [total_before, total_after], color=['red', 'green'], alpha=0.7)\n",
    "ax1.set_ylabel('Number of Records')\n",
    "ax1.set_title('Total Records: Before vs After Preprocessing')\n",
    "ax1.set_ylim(0, total_before * 1.1)\n",
    "for i, v in enumerate([total_before, total_after]):\n",
    "    ax1.text(i, v + 2000, f\"{v:,}\", ha='center', fontweight='bold')\n",
    "\n",
    "# Revenue comparison\n",
    "ax2.bar(['Before\\n(Includes Cancelled)', 'After\\n(Clean Data)'], \n",
    "        [revenue_before/1000000, revenue_after/1000000], \n",
    "        color=['red', 'green'], alpha=0.7)\n",
    "ax2.set_ylabel('Revenue (‚Çπ Millions)')\n",
    "ax2.set_title('Total Revenue: Before vs After Preprocessing')\n",
    "for i, v in enumerate([revenue_before/1000000, revenue_after/1000000]):\n",
    "    ax2.text(i, v + 1, f\"‚Çπ{v:.2f}M\", ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì 7. Conclusion & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üéØ CONCLUSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "conclusion = \"\"\"\n",
    "KEY FINDINGS:\n",
    "1. ‚ùå 14.21% of orders are Cancelled - significantly impacts revenue\n",
    "2. ‚ùå 6.04% have missing Amount values - prevents accurate calculations\n",
    "3. ‚ùå All dates are strings - blocks time-series analysis\n",
    "4. ‚úÖ No duplicate rows - data integrity is good\n",
    "5. ‚ö†Ô∏è  2,343 orders with zero/negative amounts need investigation\n",
    "\n",
    "RECOMMENDED ACTION:\n",
    "Implement preprocessing in data_processor.py to:\n",
    "- Filter out cancelled orders automatically\n",
    "- Handle NULL/invalid amounts\n",
    "- Parse dates to proper DATE type\n",
    "- Add derived time columns (year, month, quarter)\n",
    "\n",
    "EXPECTED BENEFITS:\n",
    "‚úÖ ~10% improvement in revenue accuracy\n",
    "‚úÖ Enable YoY and trend analysis\n",
    "‚úÖ Production-ready data quality\n",
    "‚úÖ Reliable business insights\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Review this analysis with stakeholders\n",
    "2. Implement preprocessing pipeline\n",
    "3. Re-run analysis on cleaned data\n",
    "4. Update documentation\n",
    "5. Deploy to production\n",
    "\"\"\"\n",
    "\n",
    "print(conclusion)\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä Analysis Complete - Notebook Ready for Interview Reference\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}